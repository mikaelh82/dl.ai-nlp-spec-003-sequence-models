{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74f016d-4f10-4be8-b6ff-ed92f997478d",
   "metadata": {},
   "source": [
    "# Deep N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2c42733-354f-482b-8282-a73ef35e7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random as  rnd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import w1_unittest\n",
    "\n",
    "\n",
    "# set random seed\n",
    "rnd.seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97b57d-0b64-4590-b2ec-55aba4a4aa42",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "978116d3-504c-40a7-a05d-9a3381121ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of line: 125097\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "dirname = \"data/\"\n",
    "path = \"shakespeare_data.txt\"\n",
    "\n",
    "with open(os.path.join(dirname, path)) as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            lines.append(line)\n",
    "\n",
    "n_lines = len(lines)\n",
    "print(f'Number of line: {n_lines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60d117d5-0e2d-4d90-9ef8-ded8b844b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENVOLIO\tHere were the servants of your adversary,\n",
      "And yours, close fighting ere I did approach:\n",
      "I drew to part them: in the instant came\n",
      "The fiery Tybalt, with his sword prepared,\n",
      "Which, as he breathed defiance to my ears,\n",
      "He swung about his head and cut the winds,\n",
      "Who nothing hurt withal hiss'd him in scorn:\n",
      "While we were interchanging thrusts and blows,\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(lines[506: 514]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebfdc70-b281-42a5-8508-c813a665a37f",
   "metadata": {},
   "source": [
    "# Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60e72f49-ead9-47d6-80e2-d917485ac674",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n'.join(lines)\n",
    "vocab = sorted(set(text))\n",
    "vocab.insert(0, '[UNK]') # Special character for every unknown\n",
    "vocab.insert(1, \"\") # Empty character for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32fde170-5ca5-4137-a45e-43faaf32d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab has 82 unique characters\n",
      "Unique character: [UNK]  \t \n",
      "   ! $ & ' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] a b c d e f g h i j k l m n o p q r s t u v w x y z |\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab has {len(vocab)} unique characters\")\n",
    "print(f\"Unique character: {' '.join(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006822f0-63bf-4e02-8c44-62a7dab2cc61",
   "metadata": {},
   "source": [
    "# Convert a line to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa7b97e9-f665-44ae-a2e0-772770172fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'H' b'e' b'l' b'l' b'o' b' ' b'w' b'o' b'r' b'l' b'd' b'!'], shape=(12,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "msg = \"Hello world!\"\n",
    "chars = tf.strings.unicode_split(msg, input_encoding=\"UTF-8\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8d72e9b-e033-4783-a4a4-7d08464b1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8d82541-8f1f-4b62-9563-2d6edb6a8ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int64, numpy=array([34, 59, 66, 66, 69,  4, 77, 69, 72, 66, 58,  5])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49f3ab91-3e83-45ef-b4b5-ac5d4326ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line, vocab):\n",
    "    \"\"\"\n",
    "    Converts a line of text into a tensor of integer values representing characters.\n",
    "\n",
    "    Args:\n",
    "        line (str): A single line of text.\n",
    "        vocab (list): A list containing the vocabulary of unique characters.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor(dtype=int64): A tensor containing integers (unicode values) corresponding to the characters in the `line`.\n",
    "    \"\"\"\n",
    "\n",
    "    chars = tf.strings.unicode_split(line, 'UTF-8')\n",
    "    ids = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)(chars)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1da4e3af-f8c2-456f-9e9f-c42aefeed1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [55 56 57  4 78 79 80]\n",
      "Output type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "tmp_ids = line_to_tensor('abc xyz', vocab)\n",
    "print(f\"Result: {tmp_ids}\")\n",
    "print(f\"Output type: {type(tmp_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "762ec40a-001f-44ab-bf47-4992441489cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll test passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "w1_unittest.test_line_to_tensor(line_to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb7b7a-5ffe-45b3-af4a-eccf440fefb6",
   "metadata": {},
   "source": [
    "# Convert a tensor of ids to a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "456d83d8-ce65-48e6-8ee1-00e2c0fc08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_converted = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True)(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e21bb44f-5369-479d-8876-71dfe23ec46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=string, numpy=\n",
       "array([b'H', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd',\n",
       "       b'!'], dtype=object)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d07491b-04ee-47d5-b997-a1df3c2e0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_converted = tf.strings.reduce_join(chars_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3cfbcce-e3e9-45a5-8e3f-135dab3dcd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Hello world!'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e5f6af6-9fe7-418d-ba26-8100843d714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids, vocab):\n",
    "    \"\"\"\n",
    "    Converts a tensor of integer values into human-readable text.\n",
    "\n",
    "    Args:\n",
    "        ids (tf.Tensor): A tensor containing integer values (unicode IDs).\n",
    "        vocab (list): A list containing the vocabulary of unique characters.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the characters in human-readable format.\n",
    "    \"\"\"\n",
    "\n",
    "    chars = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None, invert=True) (ids)\n",
    "    return tf.strings.reduce_join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4b79a28-3697-4fce-8d1e-f86f08a60660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello world!'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_ids(ids, vocab).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9fffd-1f1a-405a-9e3e-765ff7ea0215",
   "metadata": {},
   "source": [
    "# Prepare data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc560f36-21c9-4ad0-a175-ad074f7b6b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training lines: 124097\n",
      "Number of validation lines: 1000\n"
     ]
    }
   ],
   "source": [
    "train_lines = lines[:-1000]\n",
    "test_lines = lines[-1000:]\n",
    "\n",
    "print(f'Number of training lines: {len(train_lines)}')\n",
    "print(f'Number of validation lines: {len(test_lines)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6002f8-510e-464a-aa2c-b9487c159cb6",
   "metadata": {},
   "source": [
    "# Create tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8e80302-b5c2-4c31-86d6-8af89cbd3569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(26,), dtype=int64, numpy=\n",
       "array([34, 59, 66, 66, 69,  4, 77, 69, 72, 66, 58,  5,  3, 33, 59, 68, 59,\n",
       "       72, 55, 74, 63, 76, 59,  4, 27, 35])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = line_to_tensor(\"\\n\".join([\"Hello world!\", \"Generative AI\"]), vocab)\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55dd27f6-23be-40a6-9781-2bef236b1804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "ids_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ae814c7-483a-4133-a355-7e4e5b763ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'H', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l']\n"
     ]
    }
   ],
   "source": [
    "print([text_from_ids(ids, vocab).numpy() for ids in ids_dataset.take(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c41d3b8-9e5b-4c7c-9629-20881f289b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "data_generator = ids_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3711ea94-6b11-476a-8e59-36ba79b302a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello world'\n",
      "b'!\\nGenerativ'\n"
     ]
    }
   ],
   "source": [
    "for seq in data_generator.take(2):\n",
    "    print(text_from_ids(seq, vocab).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae88e07-1902-49fd-ade0-095cde57027e",
   "metadata": {},
   "source": [
    "# Generate input and output for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b216b09-c559-4596-acc5-09b22f25e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    \"\"\"\n",
    "    Splits the input sequence into two sequences, where one is shifted by one position.\n",
    "\n",
    "    Args:\n",
    "        sequence (tf.Tensor or list): A list of characters or a tensor.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor, tf.Tensor: Two tensors representing the input and output sequences for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c69877c-d7cb-4388-ac5d-1a0e346d9647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc6824-c5b6-4bcc-aeda-16b2e104cb76",
   "metadata": {},
   "source": [
    "# Create batch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c06c0af3-81d7-40e2-b5ac-0c1f0834441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_dataset(lines, vocab, seq_length=100, batch_size=64):\n",
    "    \"\"\"\n",
    "    Creates a batch dataset from a list of text lines.\n",
    "\n",
    "    Args:\n",
    "        lines (list): A list of strings with the input data, one line per row.\n",
    "        vocab (list): A list containing the vocabulary.\n",
    "        seq_length (int): The desired length of each sample.\n",
    "        batch_size (int): The batch size.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A batch dataset generator.\n",
    "    \"\"\"\n",
    "    BUFFER_SIZE = 10000\n",
    "    ids = line_to_tensor('\\n'.join(lines), vocab)\n",
    "    dataset_ids = tf.data.Dataset.from_tensor_slices(ids)\n",
    "\n",
    "    data_generator = dataset_ids.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "    dataset_xy = data_generator.map(split_input_target)\n",
    "\n",
    "    dataset = dataset_xy.shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d28effd3-c3f0-45c3-99fd-c307ddc01387",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_batch_dataset(train_lines[1:100], vocab, seq_length=16, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5a90fe9-5acf-4e3e-9ba9-af06feacf79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b's hearing to divs in the brine\\nT'\n",
      "b' hearing to divi in the brine\\nTh'\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset.take(1):\n",
    "    input_ids, target_ids = batch\n",
    "    print(f'{text_from_ids(input_ids, vocab=vocab)}')\n",
    "    print(f'{text_from_ids(target_ids, vocab=vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "040e5349-b4cf-4845-a737-32fc66c0663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prints the elements into a single batch. The batch contains 2 elements: \n",
      "\n",
      "\u001b[94mInput0\t: b'and sight distra'\n",
      "\n",
      "\u001b[93mTarget0\t: b'nd sight distrac'\n",
      "\n",
      "\n",
      "\u001b[94mInput1\t: b'when in his fair'\n",
      "\n",
      "\u001b[93mTarget1\t: b'hen in his fair '\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "dataset = create_batch_dataset(train_lines[1:100], vocab, seq_length=16, batch_size=2)\n",
    "\n",
    "print(\"Prints the elements into a single batch. The batch contains 2 elements: \")\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"\\n\\033[94mInput0\\t:\", text_from_ids(input_example[0], vocab).numpy())\n",
    "    print(\"\\n\\033[93mTarget0\\t:\", text_from_ids(target_example[0], vocab).numpy())\n",
    "    \n",
    "    print(\"\\n\\n\\033[94mInput1\\t:\", text_from_ids(input_example[1], vocab).numpy())\n",
    "    print(\"\\n\\033[93mTarget1\\t:\", text_from_ids(target_example[1], vocab).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2af6b1fd-94a5-410e-8213-a15ab0aff7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mAll test passed!\n"
     ]
    }
   ],
   "source": [
    "w1_unittest.test_create_batch_dataset(create_batch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e0dd6c0-157f-4b98-b7e1-e65310030b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = create_batch_dataset(train_lines, vocab, seq_length=100, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7431ee-3047-445f-9288-aa8b7c963b3a",
   "metadata": {},
   "source": [
    "# Defining the Gated Recurrent Unit Langauge Model (GRULM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aaeaad67-8320-4581-90f8-d8776db126f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRULM(tf.keras.models.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(units=rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(units=vocab_size, activation=None)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        x, states = self.gru(x, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c90bc97-11ed-4af5-ac0c-ae70c1283ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = 82\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN layers\n",
    "rnn_units = 512\n",
    "\n",
    "model = GRULM(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units = rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fa3cf7f-5235-4be8-8fe9-d2ad7b3d9893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 100, 82), dtype=float32, sparse=False, name=keras_tensor_9>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(Input(shape=(100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3f6e9e2-652f-49ec-8224-51c87fd3147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"grulm_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"grulm_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]           │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,066</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │     \u001b[38;5;34m1,182,720\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]           │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m82\u001b[0m)        │        \u001b[38;5;34m42,066\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,778</span> (4.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,245,778\u001b[0m (4.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,778</span> (4.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,245,778\u001b[0m (4.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "01eb3e31-d773-4d86-bb60-5b45494c28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [28 27 38 46  2 42 55 74 63 59 68 57 59  4 70 59 72 60 69 72 57 59  4 77\n",
      " 63 74 62  4 77 63 66 60 75 66  4 57 62 69 66 59 72  4 67 59 59 74 63 68\n",
      " 61  3 39 55 65 59 73  4 67 79  4 60 66 59 73 62  4 74 72 59 67 56 66 59\n",
      "  4 63 68  4 74 62 59 63 72  4 58 63 60 60 59 72 59 68 74  4 61 72 59 59\n",
      " 74 63 68 61]\n",
      "Input: b'BALT\\tPatience perforce with wilful choler meeting\\nMakes my flesh tremble in their different greeting'\n",
      "\n",
      " (1, 100, 82) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input: \", input_example_batch[0].numpy()) # Lets use only the first sequence on the batch\n",
    "    print(f'Input: {text_from_ids(input_example_batch[0], vocab=vocab)}')\n",
    "    example_batch_predictions = model(tf.constant([input_example_batch[0].numpy()]))\n",
    "    print(\"\\n\",example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0f216959-165e-42e5-9faf-f00fa05dce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(82,), dtype=float32, numpy=\n",
       "array([ -9.335007  , -10.044508  ,  -3.799502  ,   7.751006  ,\n",
       "         7.382581  ,   5.946813  ,  -9.440785  ,  -9.95324   ,\n",
       "         3.911009  ,  -6.196901  ,  -7.3926563 ,   8.592711  ,\n",
       "         5.633838  ,   9.332524  , -10.640779  ,  -9.331552  ,\n",
       "        -8.409723  ,  -8.244709  , -11.856878  ,  -8.053814  ,\n",
       "        -9.172806  , -11.2245865 ,  -9.17948   , -10.480613  ,\n",
       "         8.286085  ,   8.092345  ,   6.090642  ,  -7.0127234 ,\n",
       "        -7.8652663 ,  -8.919567  ,  -9.288979  ,  -7.019684  ,\n",
       "       -10.476525  ,  -7.589359  ,  -6.1545577 ,  -8.582107  ,\n",
       "        -6.5651436 , -13.611316  , -11.747117  ,  -9.744756  ,\n",
       "        -7.3090816 ,  -4.9205675 ,  -8.930671  ,  -8.476044  ,\n",
       "        -8.429318  ,  -3.5739174 ,  -7.377135  ,  -7.4286294 ,\n",
       "        -8.729064  ,  -7.7372675 ,  -7.8771424 , -10.645777  ,\n",
       "        -8.237826  ,  -7.335555  ,   2.9264512 ,   0.79800963,\n",
       "         2.7181623 ,  -4.9360857 ,  -0.2498487 ,   4.345892  ,\n",
       "         0.8407811 ,   4.3687835 ,   3.6014984 ,  -0.5477552 ,\n",
       "        -2.0916307 ,  -3.9172127 ,   6.0932746 ,   3.8023388 ,\n",
       "         3.5425272 ,   0.656238  ,  -2.815798  ,  -9.275383  ,\n",
       "         2.872078  ,  11.937067  ,   0.8756388 ,   3.2945147 ,\n",
       "        -5.4669967 ,  -0.56330746,  -6.2166348 ,   0.44808054,\n",
       "         0.44861692,  -9.110807  ], dtype=float32)>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "77ad6d29-886a-4d6e-adc1-4af41cbd8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.math.argmax(example_batch_predictions[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "47b8d0e3-4b75-41de-9d80-9424f1b513ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([75, 44, 46, 34, 27, 59, 72, 63, 59, 68, 57, 59, 11, 63, 72, 72, 57,\n",
       "       69, 72, 67, 59, 11, 67, 63, 74, 62,  4, 62, 62, 68, 66, 75, 66,  4,\n",
       "       73, 69, 55, 69, 59, 72,  4, 69, 55, 55, 74, 73, 68, 61,  4, 46, 55,\n",
       "       79, 59,  4,  4, 67, 59,  4, 70, 55, 59, 73, 62,  4, 55, 62, 75, 55,\n",
       "       56, 66, 63,  4, 73, 68,  4, 74, 62, 59,  4, 72,  4, 57, 59, 73, 60,\n",
       "       59, 72, 59, 68, 57, 13, 73, 72, 69, 59, 68, 63, 68, 61, 73])>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "54032065-327e-4f56-98a2-ff7407f29c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = text_from_ids(input_example_batch[0], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c1970cf6-efa5-4499-8bc4-c466ce5b4a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'BALT\\tPatience perforce with wilful choler meeting\\nMakes my flesh tremble in their different greeting'>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2e7fdadb-2fc1-4d36-9cb7-4d0f4f6bf18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text = text_from_ids(sampled_indices, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6d6ed96a-f382-42bd-a4a8-f8a6c26e2cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'uRTHAerience,irrcorme,mith hhnlul soaoer oaatsng Taye  me paesh ahuabli sn the r cesferenc.sroenings'>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ebdff-ec30-44b4-b197-ab5a54bc359b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f85df1b-f616-473d-8228-992f38f0ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    \"\"\"\n",
    "    Sets the loss and optimizer for the given model\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The model to compile.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The compiled model.\n",
    "    \"\"\"\n",
    "\n",
    "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00125)\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0d7562f-65bb-42ad-94d4-8b15115e5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 287ms/step - loss: 2.2889\n",
      "Epoch 2/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 285ms/step - loss: 1.4984\n",
      "Epoch 3/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 289ms/step - loss: 1.3947\n",
      "Epoch 4/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 296ms/step - loss: 1.3484\n",
      "Epoch 5/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 298ms/step - loss: 1.3212\n",
      "Epoch 6/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 305ms/step - loss: 1.3010\n",
      "Epoch 7/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 303ms/step - loss: 1.2851\n",
      "Epoch 8/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 310ms/step - loss: 1.2726\n",
      "Epoch 9/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 304ms/step - loss: 1.2621\n",
      "Epoch 10/10\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 305ms/step - loss: 1.2541\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "# Compile the model\n",
    "model = compile_model(model)\n",
    "# Fit the model\n",
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "36759ddc-fc60-4f5b-b091-7f73da7ba529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c9855-3b2e-4384-b114-fb8173bf3aae",
   "metadata": {},
   "source": [
    "# Calculate perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ba009326-98f0-49b2-a066-2c159c9f315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_perplexity(preds, target):\n",
    "    \"\"\"\n",
    "    Function to calculate the log perplexity of a model.\n",
    "\n",
    "    Args:\n",
    "        preds (tf.Tensor): Predictions of a list of batches of tensors corresponding to lines of text.\n",
    "        target (tf.Tensor): Actual list of batches of tensors corresponding to lines of text.\n",
    "\n",
    "    Returns:\n",
    "        float: The log perplexity of the model.\n",
    "    \"\"\"\n",
    "    PADDING_ID = 1\n",
    "    #print(f'Preds: {preds}')\n",
    "    print(f'preds.shape[-1]: {preds.shape[-1]}')\n",
    "    print(f'preds.shape: {preds.shape}') # [1, 41573, 82]\n",
    "    print(f'one hot shape: {tf.one_hot(target, preds.shape[-1]).shape}')\n",
    "    print(f'one hot[0][0]: {tf.one_hot(target, preds.shape[-1])[0][0]}')\n",
    "    print(f'target shape: {target.shape}')\n",
    "    print(f'target[0][0]: {target[0][0]}')\n",
    "    print(f'one hot[0][0][31]: {tf.one_hot(target, preds.shape[-1])[0][0][31]}')\n",
    "\n",
    "    # preds are a tensor of logprobs of shape [1, 41573, 82] which means for each word there exist logprobs in relation to vocab\n",
    "    # Target has shape [1, 41573] where one item is the id of the target word. To be compatibe and to be able to calculate\n",
    "    # the sum of the logprobs we need to convert the target to one-hot representation with shape [1, 41573, 82]\n",
    "    log_p = np.sum(preds * tf.one_hot(target, preds.shape[-1]), axis=-1) # vector multiplication across the last axis gives shape [1, 41573]\n",
    "    print(f'target.shape: {target.shape}')\n",
    "    print(f'np.equal(target, PADDING_ID): {np.equal(target, PADDING_ID)}')\n",
    "    non_pad = 1.0 - np.equal(target, PADDING_ID)\n",
    "    print(f'non-pad: {non_pad}')\n",
    "    print(f'non-pad.shape: {non_pad.shape}')\n",
    "    print(f'log_p.shape: {log_p.shape}')\n",
    "    log_p = log_p * non_pad\n",
    "\n",
    "    log_ppx = np.sum(log_p, axis = -1) / np.sum(non_pad, axis=-1)\n",
    "    log_ppx = np.mean(log_ppx)\n",
    "\n",
    "    return -log_ppx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73dbfe8f-5f6d-4f94-8480-5e593a059a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mAll test passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/bvrtrtcd4qxgkzx7v4rk09m40000gn/T/ipykernel_47437/1988947837.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  log_ppx = np.sum(log_p, axis = -1) / np.sum(non_pad, axis=-1)\n"
     ]
    }
   ],
   "source": [
    "w1_unittest.test_test_model(log_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc25d501-a5b0-4a8b-adab-1e028122ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[53, 31, 78, ..., 68, 74, 54]]>\n",
      "tf.Tensor([53 31 78 ... 68 74 54], shape=(41574,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "eval_text = '\\n'.join(test_lines)\n",
    "eval_ids = line_to_tensor([eval_text], vocab)\n",
    "print(eval_ids)\n",
    "print(tf.squeeze(eval_ids, axis=0))\n",
    "input_ids, target_ids = split_input_target(tf.squeeze(eval_ids, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d34800ba-1c35-4b8d-b5b2-b92ba0e7ea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(41573,), dtype=int64, numpy=array([31, 78, 59, ..., 68, 74, 54])>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f32ceffc-daac-4b49-ac34-003350c55cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 41573), dtype=int64, numpy=array([[31, 78, 59, ..., 68, 74, 54]])>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(target_ids, 0) # Seems model takes a row vector thereby needs to expand the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18960fd4-7ec9-4303-a070-bfe19ba9588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, status = model(tf.expand_dims(input_ids, 0), training=False, states=None, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "02029eba-b326-4c43-b87f-ac981f3228cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape[-1]: 82\n",
      "preds.shape: (1, 41573, 82)\n",
      "one hot shape: (1, 41573, 82)\n",
      "one hot[0][0]: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "target shape: (1, 41573)\n",
      "target[0][0]: 31\n",
      "one hot[0][0][31]: 1.0\n",
      "target.shape: (1, 41573)\n",
      "np.equal(target, PADDING_ID): [[False False False ... False False False]]\n",
      "non-pad: [[1. 1. 1. ... 1. 1. 1.]]\n",
      "non-pad.shape: (1, 41573)\n",
      "log_p.shape: (1, 41573)\n",
      "The log perplexity and perplexity of your model are -10.416288321936621 and 2.9940804110460913e-05 respectively\n"
     ]
    }
   ],
   "source": [
    "#Get the log perplexity\n",
    "log_ppx = log_perplexity(preds, tf.expand_dims(target_ids, 0))\n",
    "print(f'The log perplexity and perplexity of your model are {log_ppx} and {np.exp(log_ppx)} respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa218b86-8768-4e6e-bb88-206df5eed2c8",
   "metadata": {},
   "source": [
    "# Generating language with your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "33d64007-0385-4870-a371-716c4eee8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_random_sampling(log_probs, temperature=1.0):\n",
    "    \"\"\"Temperature Random sampling from a categorical distribution. The higher the temperature, the more \n",
    "       random the output. If temperature is close to 0, it means that the model will just return the index\n",
    "       of the character with the highest input log_score\n",
    "    \n",
    "    Args:\n",
    "        log_probs (tf.Tensor): The log scores for each characeter in the dictionary\n",
    "        temperature (number): A value to weight the random noise. \n",
    "    Returns:\n",
    "        int: The index of the selected character\n",
    "    \"\"\"\n",
    "   # Generate uniform random numbers with a slight offset to avoid log(0)\n",
    "    u = tf.random.uniform(minval=1e-6, maxval=1.0 - 1e-6, shape=log_probs.shape)\n",
    "    \n",
    "    # Apply the Gumbel distribution transformation for randomness\n",
    "    g = -tf.math.log(-tf.math.log(u))\n",
    "    \n",
    "    # Adjust the logits with the temperature and choose the character with the highest score\n",
    "    return tf.math.argmax(log_probs + g * temperature, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5999b209-9454-42e5-bc2d-506ef170e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeModel(tf.keras.Model):\n",
    "    def __init__(self, model, vocab, temperature=1.0):\n",
    "        \"\"\"\n",
    "        A generative model for text generation.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model): The underlying model for text generation.\n",
    "            vocab (list): A list containing the vocabulary of unique characters.\n",
    "            temperature (float, optional): A value to control the randomness of text generation. Defaults to 1.0.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        \"\"\"\n",
    "        Generate a single character and update the model state.\n",
    "\n",
    "        Args:\n",
    "            inputs (string): The input string to start with.\n",
    "            states (tf.Tensor): The state tensor.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor, states: The predicted character and the current GRU state.\n",
    "        \"\"\"\n",
    "        # Convert strings to token IDs.\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Transform the inputs into tensors\n",
    "        input_ids = line_to_tensor(inputs, self.vocab)\n",
    "        input_ids = input_ids.to_tensor()\n",
    "        # Predict the sequence for the given input_ids. Use the states and return_state=True\n",
    "        predicted_logits, states = self.model(input_ids, states=states, return_state=True)\n",
    "        tf.print(f'States: {states}')\n",
    "        # Get only last element of the sequence\n",
    "        print(f'predicted logits.shape: {predicted_logits.shape}')\n",
    "        print(f'Predicted logits: {predicted_logits}')\n",
    "        predicted_logits = predicted_logits[0, -1, :]\n",
    "        print(f'Predicted logits: {predicted_logits}')\n",
    "        tf.print(\"Predicted logits:\", predicted_logits)\n",
    "        # Use the temperature_random_sampling to generate the next character. \n",
    "        predicted_ids = temperature_random_sampling(predicted_logits, self.temperature)\n",
    "        # Use the chars_from_ids to transform the code into the corresponding char\n",
    "        predicted_chars = text_from_ids([predicted_ids], self.vocab)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Return the characters and model state.\n",
    "        return tf.expand_dims(predicted_chars, 0), states\n",
    "    \n",
    "    def generate_n_chars(self, num_chars, prefix):\n",
    "        \"\"\"\n",
    "        Generate a text sequence of a specified length, starting with a given prefix.\n",
    "\n",
    "        Args:\n",
    "            num_chars (int): The length of the output sequence.\n",
    "            prefix (string): The prefix of the sequence (also referred to as the seed).\n",
    "\n",
    "        Returns:\n",
    "            str: The generated text sequence.\n",
    "        \"\"\"\n",
    "        states = None\n",
    "        next_char = tf.constant([prefix])\n",
    "        result = [next_char]\n",
    "        for n in range(num_chars):\n",
    "            print(f'Generating one step based on char: {next_char}')\n",
    "            next_char, states = self.generate_one_step(next_char, states=states)\n",
    "            result.append(next_char)\n",
    "\n",
    "        return tf.strings.join(result)[0].numpy().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "27f9d9d1-178e-4f50-b95b-a4ce6a7f5a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating one step based on char: [b' ']\n",
      "predicted logits.shape: (1, None, 82)\n",
      "Predicted logits: Tensor(\"grulm_1_1/dense_1_1/Add:0\", shape=(1, None, 82), dtype=float32)\n",
      "Predicted logits: Tensor(\"strided_slice:0\", shape=(82,), dtype=float32)\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'h']\n",
      "predicted logits.shape: (1, None, 82)\n",
      "Predicted logits: Tensor(\"grulm_1_1/dense_1_1/Add:0\", shape=(1, None, 82), dtype=float32)\n",
      "Predicted logits: Tensor(\"strided_slice:0\", shape=(82,), dtype=float32)\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-10.1960106 -10.7844095 2.33636236 ... 5.66943312 -4.81247616 -6.25971889]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'i']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.32451153 -7.16948891 -1.90413046 ... -0.666704714 1.52439725 -4.92010784]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b'd']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.70841599 -6.09378624 1.50918448 ... 2.20626831 -2.42090607 -2.81863379]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'd']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.70841599 -6.09378624 1.50918448 ... 2.20626831 -2.42090607 -2.81863379]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b'h']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-10.1960106 -10.7844095 2.33636236 ... 5.66943312 -4.81247616 -6.25971889]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b'h']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-10.1960106 -10.7844095 2.33636236 ... 5.66943312 -4.81247616 -6.25971889]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'o']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.33577728 -6.36693287 -3.48586202 ... 0.468699425 -0.22430177 -1.65164924]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b'h']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-10.1960106 -10.7844095 2.33636236 ... 5.66943312 -4.81247616 -6.25971889]\n",
      "Generating one step based on char: [b'a']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.26586294 -6.70649099 -0.893662333 ... 3.90012336 -0.575197 -5.62963438]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b'h']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-10.1960106 -10.7844095 2.33636236 ... 5.66943312 -4.81247616 -6.25971889]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'o']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.33577728 -6.36693287 -3.48586202 ... 0.468699425 -0.22430177 -1.65164924]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      " he ind d the the o thathe ont th \n",
      "\n",
      "________________________________________________________________________________\n",
      "Generating one step based on char: [b'Dear']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-8.99552155 -8.39219475 -1.7566458 ... -0.836163938 -3.45797634 -8.64504814]\n",
      "Generating one step based on char: [b'l']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.09848356 -6.45290852 -0.449600458 ... 3.2574141 -3.65111732 -2.73272634]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b's']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.51846647 -6.28480053 0.0229211375 ... -0.339009702 -2.22791409 -3.42637396]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b'h']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-10.1960106 -10.7844095 2.33636236 ... 5.66943312 -4.81247616 -6.25971889]\n",
      "Generating one step based on char: [b'i']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.32451153 -7.16948891 -1.90413046 ... -0.666704714 1.52439725 -4.92010784]\n",
      "Generating one step based on char: [b's']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.51846647 -6.28480053 0.0229211375 ... -0.339009702 -2.22791409 -3.42637396]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'm']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-4.40935755 -4.31214762 -0.228737593 ... 5.2360487 -2.55123973 -2.41689444]\n",
      "Generating one step based on char: [b'i']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.32451153 -7.16948891 -1.90413046 ... -0.666704714 1.52439725 -4.92010784]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'd']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.70841599 -6.09378624 1.50918448 ... 2.20626831 -2.42090607 -2.81863379]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b's']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.51846647 -6.28480053 0.0229211375 ... -0.339009702 -2.22791409 -3.42637396]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b's']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.51846647 -6.28480053 0.0229211375 ... -0.339009702 -2.22791409 -3.42637396]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b'd']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.70841599 -6.09378624 1.50918448 ... 2.20626831 -2.42090607 -2.81863379]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b's']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.51846647 -6.28480053 0.0229211375 ... -0.339009702 -2.22791409 -3.42637396]\n",
      "Generating one step based on char: [b'u']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.08630419 -6.45204163 -0.924650133 ... -0.242937565 -1.72284925 -8.73980331]\n",
      "Generating one step based on char: [b'r']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.05260563 -6.18078423 -0.181852043 ... 1.25518429 -3.39865947 -3.90873075]\n",
      "Dearle s this t mine d ses nd t sur, \n",
      "\n",
      "________________________________________________________________________________\n",
      "Generating one step based on char: [b'KING']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-8.05975628 -8.25442219 8.43416595 ... -7.43911409 -0.909278333 -4.96061802]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'd']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.70841599 -6.09378624 1.50918448 ... 2.20626831 -2.42090607 -2.81863379]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'm']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-4.40935755 -4.31214762 -0.228737593 ... 5.2360487 -2.55123973 -2.41689444]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'a']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.26586294 -6.70649099 -0.893662333 ... 3.90012336 -0.575197 -5.62963438]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'm']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-4.40935755 -4.31214762 -0.228737593 ... 5.2360487 -2.55123973 -2.41689444]\n",
      "Generating one step based on char: [b'.']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-4.04065847 -4.03231621 6.69721508 ... -4.67443371 -5.00293875 2.81062484]\n",
      "Generating one step based on char: [b'\\n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.77592134 -6.22483444 -5.49943542 ... 0.792698205 -3.74519491 -0.200553432]\n",
      "Generating one step based on char: [b'W']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-4.10043192 -4.79918337 3.60347652 ... 1.4818753 -2.60997462 -1.84381127]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'y']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.01022434 -7.43423653 1.37747335 ... -2.41673493 -0.813858092 -4.54165792]\n",
      "Generating one step based on char: [b'o']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.33577728 -6.36693287 -3.48586202 ... 0.468699425 -0.22430177 -1.65164924]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'a']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.26586294 -6.70649099 -0.893662333 ... 3.90012336 -0.575197 -5.62963438]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b'e']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-7.46717787 -7.47703123 -1.03507066 ... 2.33624244 -1.63298929 -6.67454529]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'o']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.33577728 -6.36693287 -3.48586202 ... 0.468699425 -0.22430177 -1.65164924]\n",
      "Generating one step based on char: [b'n']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.20559216 -6.43868494 0.286119491 ... 0.550783157 -1.28012908 -3.82057714]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b'g']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-5.22646046 -4.97729301 -0.13268289 ... 0.491914392 -1.54649699 -3.00833225]\n",
      "Generating one step based on char: [b' ']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-9.40867424 -9.60759926 -8.10737514 ... 1.93442428 -4.65694284 -6.42707968]\n",
      "Generating one step based on char: [b's']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.51846647 -6.28480053 0.0229211375 ... -0.339009702 -2.22791409 -3.42637396]\n",
      "Generating one step based on char: [b't']\n",
      "States: Tensor(\"grulm_1_1/gru_1_1/while:4\", shape=(1, 512), dtype=float32)\n",
      "Predicted logits: [-6.49842691 -7.26504469 1.46763873 ... 3.67960119 -1.54780555 -2.61378908]\n",
      "KING d me ane m.\n",
      "We yon ane on g sth \n",
      "\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(272)\n",
    "gen = GenerativeModel(model, vocab, temperature=0.5)\n",
    "\n",
    "print(gen.generate_n_chars(32, \" \"), '\\n\\n' + '_'*80)\n",
    "print(gen.generate_n_chars(32, \"Dear\"), '\\n\\n' + '_'*80)\n",
    "print(gen.generate_n_chars(32, \"KING\"), '\\n\\n' + '_'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f59c699-4873-454b-896e-c31872c764e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted logits.shape: (1, None, 82)\n",
      "predicted logits.shape: (1, None, 82)\n",
      "ROMEO ELLINGELFise de s beyolaranthindint asepayo r.\n",
      "BEx an atad.\n",
      "To inoul miling woout, KI\n",
      "Whamy omand ntw d,\n",
      "Herithan AToulon ter ay Yoour old thand.\n",
      "ANYom, cond woncoul areealkes  sthe my thise astither l wnomeno netond cey che steaiveded, GO\t|\n",
      "LA were ho'str,\n",
      "Whay, areceth the,\n",
      "SS\tTHI baby I mimulingreth im is wanowaf yourlobe inu witar fisce umanthale, setanondoveronthintoowindormyouchithenive pe fllin\tMON\t|\n",
      "FFovein\tTRO, thtigre nd ERDESIGAne rere,\n",
      "RCUEDorise m ine wam s thett thather f f\n",
      "Thange agimathist ndarer, jer tht wind f foulan hand blatheauleves;\n",
      "BAn nd,\n",
      "ASAndshie,\n",
      "Tho I anendobree n bato; th esund'sthe d gen tite;\n",
      "TERAns ple LESHAngomecelll; angr sind our wimangowis s t in ft gind mono mavatre d dithes dur\n",
      "D\tN\tICEUCKI s ndelanount t tenee,\n",
      "Busthte's se, t hecinde of t;\n",
      "Toune ht 'S, h n?\n",
      "K\tHe t ye our, ty net s sowalsond g f we, othore,\n",
      "the onowanayo woncaneais d te cl a hit tuge t aninieyond owhare t IIAyow hind s lingh wns we ye atha fo nthoubl t her andedrmar,\n",
      "Fis mouted, t\n",
      " \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.5743057727813721\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(np.random.randint(1, 1000))\n",
    "gen = GenerativeModel(model, vocab, temperature=0.8)\n",
    "import time\n",
    "start = time.time()\n",
    "print(gen.generate_n_chars(1000, \"ROMEO \"), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "824d77fa-25a4-4cb0-9dbd-14e6414290ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b25fdb79-1a4a-40d0-acf3-7fc97976eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "04982f69-6c17-4747-8526-10ad9f4ce6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5e73e-55e6-4597-beca-96c22ad2ce06",
   "metadata": {},
   "source": [
    "# Important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b49e89-51e6-431e-aa78-d5fba8e02147",
   "metadata": {},
   "source": [
    "The number of `rnn_units` doesnt correspond to how many time-steps or time-step-computation unit. It instead sets the length or the dimension of the hidden state h. For example, if the number of `rnn-units`\n",
    " is `512` then the dimension of h is `[1, 512]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01612a-136f-4fd3-90e3-33c0e843f957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
