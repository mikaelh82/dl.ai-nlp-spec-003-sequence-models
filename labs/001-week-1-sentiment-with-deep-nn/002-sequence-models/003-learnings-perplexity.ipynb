{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd583308-b060-4e33-935e-4a82d39bde65",
   "metadata": {},
   "source": [
    "# Introduction to Perplexity in Language Modeling\n",
    "\n",
    "The perplexity is a metric that measures how well a probability model predicts a sample and it is commonly used to evaluate language models. It is defined as: \n",
    "\n",
    "$$P(W) = \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{i-1})}}$$\n",
    "\n",
    "Where  $P()$ denotes probability and $w_i$ denotes the i-th word, so $P(w_i| w_1,...,w_{i-1})$ is the probability of word $i$, given all previous words ($1$ to $i-1$).\n",
    "As an implementation hack, you would usually take the log of that formula (so the computation is less prone to underflow problems). You would also need to take care of the padding, since you do not want to include the padding when calculating the perplexity (to avoid an artificially good metric).\n",
    "\n",
    "After taking the logarithm of $P(W)$ you have:\n",
    "\n",
    "$$log P(W) = {\\log\\left(\\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{i-1})}}\\right)}$$\n",
    "\n",
    "\n",
    "$$ = \\log\\left(\\left(\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{i-1})}\\right)^{\\frac{1}{N}}\\right)$$\n",
    "\n",
    "$$ = \\log\\left(\\left({\\prod_{i=1}^{N}{P(w_i| w_1,...,w_{i-1})}}\\right)^{-\\frac{1}{N}}\\right)$$\n",
    "\n",
    "$$ = -\\frac{1}{N}{\\log\\left({\\prod_{i=1}^{N}{P(w_i| w_1,...,w_{i-1})}}\\right)} $$\n",
    "\n",
    "$$ = -\\frac{1}{N}{{\\sum_{i=1}^{N}{\\log P(w_i| w_1,...,w_{i-1})}}} $$\n",
    "\n",
    "## Understanding Perplexity\n",
    "- **Lower Perplexity:** A lower perplexity indicates that the model predicts the words with higher likelihood, which means the model is more confident in its predictions.\n",
    "- **Higher Perplexity:** Conversely, a higher perplexity suggests that the model is less sure about its predictions.\n",
    "Perplexity can be thought of as the weighted average branching factor of a language; it is the number of choices the model feels it has, on average, when predicting the next symbol.\n",
    "\n",
    "## Why Use Perplexity?\n",
    "**Model Comparisons:** Perplexity provides a standard way to compare different language models. A model with a lower perplexity on a test set is generally considered to be better at predicting the sample.\n",
    "Model Improvement: It can also serve as an objective function during the training of a language model, with the goal of minimizing perplexity, thus improving the model's performance.\n",
    "\n",
    "## Limitations of Perplexity\n",
    "While perplexity is a widely used metric, it does have limitations. It assumes that the model and test data are from the same distribution, and it may not always correlate perfectly with human judgment of model quality, especially in tasks like machine translation or text generation.\n",
    "\n",
    "## Applications and Limitations of Perplexity\n",
    "\n",
    "Perplexity is particularly useful in the context of language modeling, where the goal is often to predict the next word in a sequence. It provides a way to evaluate how well a model has learned to perform this task:\n",
    "\n",
    "- **Applications**: In areas such as speech recognition, machine translation, and text generation, perplexity serves as a key metric to gauge how well the model understands the language patterns.\n",
    "\n",
    "- **Limitations**: However, perplexity alone may not capture all aspects of model performance, particularly in tasks that require semantic understanding or generation of coherent text. It is a measure of the model's uncertainty, not necessarily the quality or coherence of the text it might generate.\n",
    "\n",
    "## Correlation with Human Judgment\n",
    "\n",
    "The correlation between perplexity and the human judgment of language model quality can be imperfect. For example:\n",
    "\n",
    "- A model might achieve low perplexity by being overly conservative, thus not generating diverse or interesting text.\n",
    "- Conversely, a model could generate novel and contextually appropriate text but might have higher perplexity due to the unpredictability of creative language use.\n",
    "\n",
    "## Cross-Entropy and Perplexity\n",
    "\n",
    "Perplexity is directly related to the cross-entropy between the true distribution and the model's distribution. The cross-entropy measures the average number of bits needed to encode the data coming from the true distribution using the model's distribution.\n",
    "\n",
    "## Normalization and Perplexity Calculation\n",
    "The normalization by the length of the sequence $N$ when computing perplexity ensures that sequences of different lengths can be compared fairly. This is crucial in datasets with variable-length sequences and allows for a consistent evaluation metric across different models and corpora.\n",
    "\n",
    "## Good Perplexity\n",
    "\n",
    "**Lower Than Baseline:** A \"good\" perplexity is typically lower than some established baseline. For instance, it might be compared against the perplexity of a unigram model (a model that only considers the probability of individual words, ignoring context).\n",
    "\n",
    "**Improvement Over Training:** A perplexity that decreases over time during training indicates that the model is learning and improving its predictions.\n",
    "\n",
    "**Context-Specific Benchmarks:** What is considered \"good\" can also be highly specific to the domain or application. For language models trained on children's books, a lower perplexity is expected because of the simpler language structure, compared to models trained on more complex corpora, like legal documents.\n",
    "\n",
    "## Bad Perplexity\n",
    "**Higher Than Baseline:** A \"bad\" perplexity would be higher than a simple or baseline model, suggesting that the model is not learning the data's structure.\n",
    "\n",
    "**No Improvement Over Training:** If perplexity does not decrease, or worse, increases as training progresses, it suggests issues with the model architecture, learning process, or data representation.\n",
    "\n",
    "**High Perplexity on Simple Data:** If a model has high perplexity on data that is relatively predictable or repetitive, it indicates that the model is failing to capture even the basic patterns in the data.\n",
    "\n",
    "## Factors Influencing Good vs. Bad Perplexity\n",
    "\n",
    "**Quality of Training Data:** The diversity and quality of the training data can greatly influence perplexity. If the training data is not representative of the language patterns in the test set, even a low perplexity might not indicate a good model.\n",
    "\n",
    "**Model Complexity:** More complex models may achieve lower perplexity by capturing subtler patterns, but they may also be more prone to overfitting, which could result in poor performance on unseen data despite good perplexity scores on the training or validation sets.\n",
    "\n",
    "**Corpus Size and Diversity:** For a very diverse corpus or a corpus with a large vocabulary, a higher perplexity might be acceptable compared to a more homogeneous or smaller corpus.\n",
    "\n",
    "## Evaluating Perplexity in Practice\n",
    "\n",
    "**Relative Performance:** A good practice is to compare perplexity across several models or against known benchmarks in the field. Improvements relative to these benchmarks can indicate good perplexity.\n",
    "\n",
    "**Task-Specific Metrics:** Perplexity should be used alongside other performance metrics that are relevant to the specific task (e.g., BLEU scores for translation, ROUGE for summarization).\n",
    "\n",
    "**Human Evaluation:** Ultimately, especially for generative models, human evaluation can provide the most relevant assessment of text quality, and perplexity should not be the sole measure of a language model's capability.\n",
    "\n",
    "## Conclusion\n",
    "While perplexity is a valuable metric for comparing probabilistic models, it should be used alongside other evaluations, such as qualitative assessments of generated text and task-specific performance measures, to gain a comprehensive understanding of a model's capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b17fb7-7835-4652-b3b7-301fed501aff",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1a453-0268-46f0-874d-2c5dc979b10d",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc8d628-9bad-418d-a49f-938cea3c5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aca6a0-8304-4218-b1f4-8b9a5b063d9d",
   "metadata": {},
   "source": [
    "## Set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e8fa0e-d0ba-441d-aa0d-89ad6e6ded8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14c2c7-fe5a-4238-9b3b-344288a9de7d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b539aa-5bd8-411c-a159-4643e9dceb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load('predictions.npy')\n",
    "targets = np.load('targets.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54607b4b-6f42-46a5-ab8e-c67fc1d7ebef",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162a2a0-3652-42d1-98c1-c510103baad6",
   "metadata": {},
   "source": [
    "### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c133762b-555f-4488-8f52-edb2f7489d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab0dd9-1d7e-4f04-801e-3f221d876545",
   "metadata": {},
   "source": [
    "The targets comprise the genuine tokens within a sequence. For instance, the target data contain 32 distinct sequences, each potentially including up to 64 tokens. Sequences shorter than 64 tokens are padded with the index '0' to reach this fixed length. Conversely, sequences exceeding 64 tokens are truncated to fit this limit. Each token in a sequence is denoted by a numerical index ranging from 0 to 255, which corresponds to its position in the vocabulary. Notably, the index '0' is reserved for the 'pad' token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f68ff-d7f5-46e3-a6cb-029cdbe954c6",
   "metadata": {},
   "source": [
    "First sequence looks like following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce9efcaa-c820-4891-9af0-63f63ad6d215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105, 110,  32, 115, 117,  99, 104,  32, 100, 105, 115, 100,  97,\n",
       "       105, 110, 102, 117, 108,  32, 109,  97, 110, 110, 101, 114,  32,\n",
       "       109, 101,  32, 116, 111,  32, 119, 111, 111,  46,   1,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df2a12-87da-4bb4-a9a1-9c40a2778f12",
   "metadata": {},
   "source": [
    "Second sequence looks like following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ca082a-cfcf-4fc0-ab90-a6b601e8ebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97, 110, 110, 101,  32, 112,  97, 103, 101,   9, 110, 111, 116,\n",
       "        32, 105,  44,  32, 115, 105, 114,  59,  32, 112, 114,  97, 121,\n",
       "        32, 121, 111, 117,  44,  32, 107, 101, 101, 112,  32, 111, 110,\n",
       "        46,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71977326-19f9-4726-b4e8-80d77c392f80",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "878d922b-cfb5-4c60-835c-7fc9ee56b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5dda1e-834c-46b4-97b6-f764086217ae",
   "metadata": {},
   "source": [
    "The concept applies similarly to predictions. There are 32 predicted sequences, each consisting of up to 64 tokens. However, instead of each token being represented by a single figure between 0 and 255, every token is associated with a prediction vector of length 256. Each position in the vector corresponds to a token index in the vocabulary. It's important to note that for padded tokens, which are represented by the 'pad' token '0' in the targets, the prediction for this padding is specifically indicated at the zero index of the corresponding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f6e1f-884e-48a1-a42e-062c2152870a",
   "metadata": {},
   "source": [
    "Lets see some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99845707-4cd2-470b-84b9-e9b66f4c09eb",
   "metadata": {},
   "source": [
    "Lets investigate the target of the first sequence and token 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c04e77-e588-430e-94b4-083430a08978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea3bdf-58d1-431d-837a-3de84128bfc1",
   "metadata": {},
   "source": [
    "In the first sequence, the third token correctly corresponds to the token with index 32. Let's examine the predictions for this token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697564bd-d692-4b9f-895c-d51e4e7fb099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-15.783699  , -14.416848  , -15.512791  , -15.747061  ,\n",
       "       -15.875423  , -15.857048  , -15.714527  , -15.726427  ,\n",
       "       -15.636484  , -13.204674  , -15.7897625 , -15.5456505 ,\n",
       "       -15.627533  , -15.669703  , -15.476461  , -15.597759  ,\n",
       "       -15.612074  , -15.629346  , -15.774958  , -15.947931  ,\n",
       "       -15.6925955 , -15.850674  , -15.700855  , -15.57556   ,\n",
       "       -15.5442295 , -15.589245  , -15.796459  , -15.781776  ,\n",
       "       -15.77724   , -15.740474  , -15.735656  , -15.596254  ,\n",
       "        -0.66916656,  -9.375701  , -15.529961  , -15.690064  ,\n",
       "       -18.688759  , -15.854721  , -21.715818  ,  -4.7703843 ,\n",
       "       -18.846731  , -20.794693  , -15.685709  , -15.793209  ,\n",
       "        -6.7585335 ,  -9.853044  ,  -4.3036513 , -15.662617  ,\n",
       "       -13.796404  , -15.667776  , -19.005121  , -15.684215  ,\n",
       "       -15.78345   , -18.78386   , -16.584015  , -15.431082  ,\n",
       "       -17.811726  , -15.437679  , -11.17949   , -11.846891  ,\n",
       "       -15.628307  , -15.664791  , -15.902561  ,  -8.733591  ,\n",
       "       -15.512666  , -17.56845   , -24.032478  , -14.9834385 ,\n",
       "       -20.113865  , -29.792118  , -19.250301  , -13.802544  ,\n",
       "       -25.254175  , -18.005123  , -23.950462  , -20.407291  ,\n",
       "       -25.67591   , -21.050926  , -19.730934  , -23.458984  ,\n",
       "       -21.638294  , -23.85109   , -19.011568  , -17.59473   ,\n",
       "       -20.002735  , -23.986713  , -18.95261   , -19.850449  ,\n",
       "       -15.519598  , -17.007397  , -18.65071   , -15.188213  ,\n",
       "       -15.847374  ,  -9.203167  , -15.559748  , -15.617865  ,\n",
       "       -15.652416  ,  -9.954896  , -21.993435  ,  -2.3104897 ,\n",
       "        -2.275299  ,  -7.346492  ,  -5.052045  ,  -5.0287457 ,\n",
       "        -6.791709  , -11.044687  ,  -6.5540795 ,  -3.8848968 ,\n",
       "       -13.848402  , -17.107798  ,  -7.5930853 , -12.817877  ,\n",
       "       -15.444376  ,  -5.849354  , -13.094804  ,  -2.988068  ,\n",
       "        -1.8995523 , -12.046377  ,  -3.922975  ,  -6.088345  ,\n",
       "        -9.925751  , -11.960047  , -23.548498  , -15.654704  ,\n",
       "       -14.034978  , -15.666986  , -15.75954   , -15.707815  ,\n",
       "       -15.607798  , -15.746565  , -15.712476  , -15.413698  ,\n",
       "       -15.478844  , -15.754438  , -15.498091  , -15.698762  ,\n",
       "       -15.72828   , -15.630173  , -15.570764  , -15.771336  ,\n",
       "       -15.579793  , -15.91203   , -15.815462  , -15.575531  ,\n",
       "       -15.58486   , -15.572036  , -15.839144  , -15.654234  ,\n",
       "       -15.810878  , -15.3945465 , -15.9092245 , -15.801086  ,\n",
       "       -15.637075  , -15.647936  , -15.640862  , -15.581184  ,\n",
       "       -15.583277  , -15.699088  , -15.6168    , -15.613087  ,\n",
       "       -15.695566  , -15.703547  , -15.792339  , -15.570557  ,\n",
       "       -15.613958  , -15.615318  , -15.481691  , -15.644186  ,\n",
       "       -15.622147  , -15.656742  , -15.691233  , -15.479937  ,\n",
       "       -15.999639  , -15.489266  , -15.676739  , -15.567802  ,\n",
       "       -15.503786  , -15.613609  , -15.579342  , -15.674076  ,\n",
       "       -15.434271  , -15.700403  , -15.61838   , -15.505856  ,\n",
       "       -15.572031  , -15.523488  , -15.722835  , -15.65246   ,\n",
       "       -15.658123  , -15.565388  , -15.81936   , -15.485369  ,\n",
       "       -15.663591  , -15.597803  , -15.647606  , -15.618877  ,\n",
       "       -15.821683  , -15.723452  , -15.6322    , -15.955959  ,\n",
       "       -15.650801  , -15.7127075 , -15.7217245 , -15.540747  ,\n",
       "       -15.50329   , -15.706231  , -15.763105  , -15.586077  ,\n",
       "       -15.5942545 , -15.756175  , -15.701048  , -15.6481695 ,\n",
       "       -15.4867735 , -15.65315   , -15.65123   , -15.868278  ,\n",
       "       -15.621338  , -15.704302  , -15.514774  , -15.599232  ,\n",
       "       -15.700449  , -15.569709  , -15.595665  , -15.792137  ,\n",
       "       -15.698025  , -15.605639  , -15.775242  , -15.582329  ,\n",
       "       -15.558056  , -15.583412  , -15.757426  , -15.606953  ,\n",
       "       -15.658038  , -15.662586  , -15.662289  , -15.463791  ,\n",
       "       -15.464977  , -15.680338  , -15.804324  , -15.785232  ,\n",
       "       -15.500948  , -15.643656  , -15.496595  , -15.660987  ,\n",
       "       -15.676879  , -15.573444  , -15.585638  , -15.70054   ,\n",
       "       -15.758127  , -15.609343  , -15.55916   , -15.822226  ,\n",
       "       -15.569405  , -15.729168  , -15.671564  , -15.53212   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d715c-eba5-47db-96ac-10f6491b97ea",
   "metadata": {},
   "source": [
    "Or, more precisely, let's look at the probability that the actual token is the one with index 32 in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d24534c-2e4b-4191-ba4c-b0952cceb711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5121352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(predictions[0, 2, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f5dd1-ef50-43d9-8398-4de0c7fd27e3",
   "metadata": {},
   "source": [
    "Let’s determine if the prediction was accurate by identifying the index with the lowest log probability, which corresponds to the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a59db17-a7e0-4fe7-819c-454e42eaaf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0, 2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da4966-0e72-45d3-90fa-60f543253c39",
   "metadata": {},
   "source": [
    "This is a correct prediction, as the target index for the third token in the first sequence (sequence 0, token 2) was 32, and the token with the highest probability at this position also has an index of 32, with a probability of 0.5121325."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6afb4-ff39-402a-9d58-e36f22516b51",
   "metadata": {},
   "source": [
    "## Reshaping `targets` to same shape as `predictions`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7e59d-93fc-4cbb-b3f0-5a6c3d4eb7f5",
   "metadata": {},
   "source": [
    "We need to adjust the targets to match the dimensions of the predictions, transforming them from a single number between $0$ and $255$, which represents a specific token in the vocabulary, to a one-hot encoded vector. In this format, the one-hot vector has a value of $1$ at the index corresponding to the target token's index (previously a number between $0$ - $255$). For example, if $targets[1, 40]$ initially had a value of $1$, after reshaping, it would be represented by a one-hot vector like this: $ [0, 1, 0, 0, 0, ..., 0] $, with a length of $64$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9967607-0a0b-488f-a32f-423f3fb86019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[1, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfa7a450-4701-46c2-a2a1-5969e2f0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_targets = np.eye(predictions.shape[-1])[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8075d0e8-6408-45e2-936b-b2d61c55a10c",
   "metadata": {},
   "source": [
    "The code `reshaped_targets = np.eye(predictions.shape[-1])[targets]` reshapes the targets to have the same dimensions as the predictions by converting them into one-hot encoded vectors. This is achieved through the following steps:\n",
    "\n",
    "1. **Creating an Identity Matrix**: `np.eye(predictions.shape[-1])` generates an identity matrix of size equal to the number of classes or possible tokens (the last dimension of `predictions`). Each row in this matrix represents a one-hot encoded vector for a corresponding class.\n",
    "\n",
    "2. **Indexing with Targets**: The matrix `[targets]` uses the target indices to select the appropriate one-hot encoded vectors from the identity matrix. This effectively transforms each scalar target into a one-hot encoded vector.\n",
    "\n",
    "3. **Matching Dimensions**: The resulting `reshaped_targets` array matches the shape of `predictions`, enabling direct comparison and element-wise operations between predicted probabilities and actual target vectors. This transformation is essential for computing loss functions that require input dimensions of targets and predictions to be identical, such as categorical cross-entropy.\n",
    "\n",
    "By using this approach, we ensure that each target token is accurately represented as a one-hot vector, facilitating effective training and evaluation of classification models where predictions are also probability distributions over the same set of classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2a00032-3920-48bf-a377-241a2792e24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 256)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6f482da-0936-4c2b-a82f-0e6b63f1ad91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets[1, 40, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5786105-1b3c-48b2-bd11-8a7673a99ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets[1, 40, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "805f9388-fb9c-4c5f-903c-e4d28d4f6ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets[1, 40, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011cd365-26ee-4808-aae0-84311617bc49",
   "metadata": {},
   "source": [
    "## Summing the log probabilities\n",
    "\n",
    "As we aim to compute the following negative average log-likelihood,\n",
    "\n",
    "$$ = -\\frac{1}{N}{{\\sum_{i=1}^{N}{\\log P(w_i| w_1,...,w_{i-1})}}} $$\n",
    "\n",
    "the initial step involves calculating the sum of the log probabilities of the predicted values, each multiplied by their corresponding one-hot vectors. Since these vectors are one-hot encoded, each entry in the resultant matrix directly represents the log probability of the actual token. This ensures that only the log probabilities associated with the true token indices contribute to the sum.\n",
    "\n",
    "As an example, see following calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "729c2703-f7bc-42db-abf9-7f705eb694eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets[1, 40, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bac840ee-00e2-4466-810c-f4d49b5c4a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-36.391533  ,  -2.946434  , -36.57123   , -36.770393  ,\n",
       "       -36.335464  , -36.6263    , -36.485146  , -36.377808  ,\n",
       "       -36.43523   , -21.897081  , -36.628742  , -36.537407  ,\n",
       "       -36.42761   , -36.476738  , -36.472946  , -36.34853   ,\n",
       "       -36.506317  , -36.689102  , -36.408024  , -36.267384  ,\n",
       "       -36.523792  , -36.531082  , -36.442635  , -36.562263  ,\n",
       "       -36.627666  , -36.634056  , -36.533333  , -36.47747   ,\n",
       "       -36.67165   , -36.475838  , -36.439873  , -36.559284  ,\n",
       "        -0.05396652, -34.01696   , -36.34834   , -36.47068   ,\n",
       "       -37.786743  , -36.589767  , -43.71125   , -11.775192  ,\n",
       "       -32.293053  , -27.512966  , -36.45308   , -36.458286  ,\n",
       "       -22.550772  , -16.47274   , -28.42991   , -36.377464  ,\n",
       "       -30.13439   , -37.79309   , -37.859344  , -37.63462   ,\n",
       "       -36.533337  , -38.48908   , -35.33613   , -37.42507   ,\n",
       "       -33.745102  , -37.340454  , -21.17191   , -22.333817  ,\n",
       "       -36.7372    , -36.648296  , -36.459934  , -29.19455   ,\n",
       "       -36.67074   , -27.132431  , -34.655216  , -38.920033  ,\n",
       "       -49.55925   , -47.746876  , -42.380257  , -40.373436  ,\n",
       "       -41.017345  , -40.16396   , -39.63032   , -52.6768    ,\n",
       "       -38.153023  , -34.51109   , -33.331726  , -43.470036  ,\n",
       "       -45.484383  , -37.97882   , -32.594433  , -33.249508  ,\n",
       "       -36.54403   , -37.424587  , -41.509277  , -33.511677  ,\n",
       "       -40.25245   , -34.10744   , -22.239153  , -33.164753  ,\n",
       "       -36.56477   , -26.899239  , -36.567432  , -36.50949   ,\n",
       "       -36.570095  , -43.42507   , -43.183647  , -47.04888   ,\n",
       "       -49.03008   , -35.28754   , -46.256927  , -47.85784   ,\n",
       "       -49.66494   , -40.532017  , -42.984127  , -53.043     ,\n",
       "       -42.886436  , -45.71074   , -47.693398  , -38.059868  ,\n",
       "       -52.0928    , -46.045166  , -40.45812   , -33.94238   ,\n",
       "       -44.664043  , -49.26069   , -49.60598   , -41.800995  ,\n",
       "       -32.976295  , -43.918373  , -40.205994  , -36.63753   ,\n",
       "       -27.94623   , -36.381012  , -36.33673   , -36.701717  ,\n",
       "       -36.360012  , -36.52316   , -36.407303  , -36.26049   ,\n",
       "       -36.55874   , -36.499733  , -36.568287  , -36.453896  ,\n",
       "       -36.434074  , -36.531128  , -36.524628  , -36.722378  ,\n",
       "       -36.53926   , -36.322372  , -36.39174   , -36.580517  ,\n",
       "       -36.776173  , -36.538696  , -36.68397   , -36.44438   ,\n",
       "       -36.343487  , -36.47476   , -36.56771   , -36.42599   ,\n",
       "       -36.538624  , -36.571236  , -36.294147  , -36.39338   ,\n",
       "       -36.35589   , -36.45306   , -36.40308   , -36.53422   ,\n",
       "       -36.41846   , -36.389057  , -36.39392   , -36.57035   ,\n",
       "       -36.26744   , -36.378696  , -36.37624   , -36.461357  ,\n",
       "       -36.679237  , -36.43204   , -36.248264  , -36.393425  ,\n",
       "       -36.504936  , -36.760303  , -36.61822   , -36.44613   ,\n",
       "       -36.416103  , -36.795155  , -36.56118   , -36.52833   ,\n",
       "       -36.600697  , -36.740253  , -36.343353  , -36.588654  ,\n",
       "       -36.5471    , -36.37538   , -36.460323  , -36.32804   ,\n",
       "       -36.41838   , -36.558136  , -36.33666   , -36.48033   ,\n",
       "       -36.504326  , -36.41618   , -36.482433  , -36.533356  ,\n",
       "       -36.48678   , -36.493557  , -36.629128  , -36.387875  ,\n",
       "       -36.413895  , -36.687855  , -36.393726  , -36.509045  ,\n",
       "       -36.34131   , -36.37825   , -36.40541   , -36.510403  ,\n",
       "       -36.49904   , -36.4863    , -36.348473  , -36.474285  ,\n",
       "       -36.397003  , -36.5158    , -36.421654  , -36.5763    ,\n",
       "       -36.662693  , -36.52817   , -36.556885  , -36.572975  ,\n",
       "       -36.427177  , -36.48505   , -36.574608  , -36.491776  ,\n",
       "       -36.361313  , -36.656433  , -36.629345  , -36.616596  ,\n",
       "       -36.4572    , -36.565735  , -36.57437   , -36.49549   ,\n",
       "       -36.427277  , -36.30197   , -36.46695   , -36.59917   ,\n",
       "       -36.65111   , -36.533745  , -36.458508  , -36.62546   ,\n",
       "       -36.46426   , -36.60373   , -36.553913  , -36.55644   ,\n",
       "       -36.35411   , -36.423786  , -36.507008  , -36.674137  ,\n",
       "       -36.44249   , -36.427757  , -36.53694   , -36.426178  ,\n",
       "       -36.624786  , -36.472446  , -36.28495   , -36.440174  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1, 40, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41140685-5bd2-4d41-92e7-11b0eaf773ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.946434"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1, 40, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "078b6a71-0e4c-47eb-a2fc-e381c87e1f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9464340209960938"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(reshaped_targets[1, 40, :] * predictions[1, 40, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b6b0c-a8f7-4a47-a1ad-e28a65325889",
   "metadata": {},
   "source": [
    "Now, lets do this for all sequences and tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7cf8cd5-8278-4e9d-b0e9-34d193d729b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p = np.sum(predictions * reshaped_targets, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cbe6822-e48d-46fd-9121-aedd3edd7186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "264c359e-f035-4cf1-91a9-8d49d631ac35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.39654493,  -1.03111839,  -0.66916656, ..., -22.37672997,\n",
       "        -23.18770981, -21.84348297],\n",
       "       [ -4.58577061,  -1.13412857,  -8.53803253, ..., -20.15686035,\n",
       "        -26.83709717, -23.57501984],\n",
       "       [ -5.22238874,  -1.28241444,  -0.17312431, ..., -21.328228  ,\n",
       "        -19.85441208, -33.88444138],\n",
       "       ...,\n",
       "       [ -5.39654493, -17.29168129,  -4.36076593, ..., -20.82580185,\n",
       "        -21.06583786, -22.44311523],\n",
       "       [ -5.93131638, -14.24741745,  -0.26373291, ..., -26.74324799,\n",
       "        -18.38433075, -22.35527802],\n",
       "       [ -5.67053604,  -0.10595131,   0.        , ..., -23.33252335,\n",
       "        -28.08737564, -23.87880707]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e16a0f9-fefe-46a6-9cac-3e3dc9bffbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9464340209960938"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p[1, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac663e9d-31b2-431d-879f-a2d623479185",
   "metadata": {},
   "source": [
    "##  Adjusting for padded values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1ae2e-0dbe-479d-b99f-0b1fdb744cf9",
   "metadata": {},
   "source": [
    "One of the issues that will impact the perplexity measure and somethign that we need to adjust for is that sentences shorter than 64 tokens were padded with zeros up to the length of 64. Since the padding is the actual token with index 0 in the vocab. This will actually affect the probabilties and the perplexity measure. we need to adjust the log_p matrix for this issue.\n",
    "\n",
    "As an example see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a436da32-544c-405d-9de0-505401709692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0, 63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9080d051-f37c-475d-92a8-e61cfd35131c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets[0, 63, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "229360e8-ab5c-48c2-853f-79f90dae61f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_targets[0, 63, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccbffa-7950-4c65-b7f2-2e2274747b37",
   "metadata": {},
   "source": [
    "This implies that in the one-hot encoded vector, the first element is set to 1.0 at the position corresponding to the pad token. Consequently, this configuration influences the sum of probabilities since the calculation will include the model's estimated probability that this particular token is a padding token.\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eeb86c80-2acb-4b03-8ba7-c92a8e316989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-21.84348297,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ,\n",
       "        -0.        ,  -0.        ,  -0.        ,  -0.        ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, 63, :] * reshaped_targets[0, 63, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22fff870-9ed6-48f3-b4e0-6a5cc0d17c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.843482971191406"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions[0, 63, :] * reshaped_targets[0, 63, :])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81054a2b-c422-4afd-b41f-b6490d410fb4",
   "metadata": {},
   "source": [
    "To adjust for this, we create a `non_pad` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "182a5094-9c8d-433b-94be-7927740ea938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_pad = 1.0 - np.equal(targets, 0)\n",
    "no_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77e64ed4-3398-4184-a96b-b13b0a1b8fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76c3e0-8429-43cc-81a2-71aa0eaa6510",
   "metadata": {},
   "source": [
    "That we then multiply with the `log_p` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31245ceb-ba26-4872-9dc4-7ff76e762302",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_log_p = log_p * no_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "230f2604-58c7-496c-a713-ff8b0edf1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.39654493,  -1.03111839,  -0.66916656, ...,  -0.        ,\n",
       "         -0.        ,  -0.        ],\n",
       "       [ -4.58577061,  -1.13412857,  -8.53803253, ...,  -0.        ,\n",
       "         -0.        ,  -0.        ],\n",
       "       [ -5.22238874,  -1.28241444,  -0.17312431, ...,  -0.        ,\n",
       "         -0.        ,  -0.        ],\n",
       "       ...,\n",
       "       [ -5.39654493, -17.29168129,  -4.36076593, ...,  -0.        ,\n",
       "         -0.        ,  -0.        ],\n",
       "       [ -5.93131638, -14.24741745,  -0.26373291, ...,  -0.        ,\n",
       "         -0.        ,  -0.        ],\n",
       "       [ -5.67053604,  -0.10595131,   0.        , ...,  -0.        ,\n",
       "         -0.        ,  -0.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137d449-4833-481a-a9fb-b176486b5be7",
   "metadata": {},
   "source": [
    "## Calculating Perplexity\n",
    "\n",
    "Perplexity is a crucial metric in evaluating language models, indicating how well a model predicts a sample. The process involves three methodical steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653a2bf-47c6-4d3c-b286-5da6c58facc7",
   "metadata": {},
   "source": [
    "### Calculate Average Log Probability Per Sequence:\n",
    "Begin by summing the log probabilities for each sentence. Importantly, this summation must only include the log probabilities associated with actual tokens, excluding any padding tokens. Divide this sum by the number of actual (non-padded) tokens in the sentence to obtain the average log probability per sequence. This step ensures that each sequence is evaluated based on its content rather than its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0274ee76-ae48-498c-a3bf-545a45b6df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ppx = np.sum(real_log_p, axis = 1) / np.sum(no_pad, axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cc57b-26d6-4025-ac93-a8250c6a8a80",
   "metadata": {},
   "source": [
    "### Compute Mean Log Probability Across All Sequences:\n",
    "Once you have the average log probability for each individual sequence, the next step is to calculate the mean of these averages across all sequences. This overall mean log probability provides a single measure reflecting the model’s performance across the entire dataset, balancing out individual sequence variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "74addae7-17f0-489a-a9ad-e2e283656dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ppx = np.mean(-log_ppx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ae1322b-26b5-40f3-8196-a996a5c6fa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6211854987065033"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ppx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24aefe-7e28-4774-a8f8-d0a4b7b4f5b0",
   "metadata": {},
   "source": [
    "### Exponentiate to Obtain Perplexity:\n",
    "Since the values computed are logarithmic probabilities, to convert these back into a more interpretable measure, raise them to the power of $e$ (the base of natural logarithms). The result is the perplexity of the model, a non-logarithmic measure. A lower perplexity score indicates a model with better predictive accuracy, as it suggests less uncertainty in predicting the next word in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50108cfb-b0e0-47c2-bc77-75c8cd1621a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppx = np.exp(log_ppx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0012989c-e352-4c64-81b3-2fe0d233511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.752016923578548"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
